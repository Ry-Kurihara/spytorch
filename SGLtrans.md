# Surrogate Gradient Learning in Spiking Neural Networks

## Abstract
スパイキングニューラルネットワーク（SNN）は、効率的で多用途に用いられるソリューションである。これらのモデルをハードウェアに実装するために、様々な研究が行われているが、現実世界の入力をどのように扱い学習するかにおいての課題がいくつか存在する。従来のニューラルネットワーク（ANN）と同様に、現実世界のデータを訓練することは可能だが、バイナリ形式で行われる入出力の特性などから、最適な学習方法や実装方法が一意に定まっていないのが現状である。</br>
この論文では、SNNをトレーニングする際に一般的に遭遇する問題を段階的に説明しシナプス可塑性（Synaptic Plasticity）とオンラインデータ学習法について説明する。その後、これらの問題に対応する画期的な方法である代理勾配法についての説明に移る。

#### 個人的注釈
- SNN
  - 近年になって研究が盛んにされてきているニューラルネットワークのモデルのひとつ。RNNやSNNなどを第２世代NNと呼ぶのに対してこちらは第３世代NNと呼ばれることもある。
- シナプス可塑性
  - あるニューロンが発火することにより、次のニューロンが発火した場合、そのニューロン間どうしの結びつきがさらに強くなるという法則。実際の人間の脳はこの法則性を持っているとされる。これをSNNに適応させた学習則としてSTDP（Spike-Timing Dependent Plasticity）がある。（https://scrapbox.io/AGI/STDP）</br>
  SNNの教師なし学習則として広く用いられている。2018年12月頃にリリースされたSNN用のフレームワークBindsNetにもこの学習則は実装されている。しかしBindsNetにはなぜか教師あり学習則が実装されていない・・・

## 1章 Introduction
機械学習の分野では、内部状態が時間とともに変化するNNの一種であるRNNがリアルタイムのパターン認識とノイズの多い系列データの学習に非常に効果的であることがわかってる。この類似性に基づき、RNNとSNNの積分発火モデル（LIFモデル）を組み合わせたニューロンモデルが提案されてきている。
1. F. Zenke and S. Ganguli, “SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks,”
Neural Computation, vol. 30, no. 6, pp. 1514–1541, Apr. 2018.
2. G. Bellec, D. Salaj, A. Subramoney, R. Legenstein, and W. Maass, “Long short-term memory and
Learning-to-learn in networks of spiking neurons,” in Advances in Neural Information ProcessingSystems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds. Curran Associates, Inc., 2018, pp. 795–805.
3. J. Kaiser, H. Mostafa, and E. Neftci, “Synaptic plasticity for deep continuous local learning,” arXiv preprint arXiv:1812.10766, 2018.
4. A. Tavanaei, M. Ghodrati, S. R. Kheradpisheh, T. Masquelier, and A. Maida, “Deep learning in
spiking neural networks,” Neural Networks, Dec. 2018.

大規模RNNによる大規模データ学習は、時系列ノイズや空間的依存性により困難な場面が多い。SNNやバイナリRNNにおいても同様であり、出力のバイナリ性質によってさらに困難になる。</br>
隠れ層ユニットなしの2層SNNでは、多くの効率的なトレーニングによる結果が報告されているが、大規模データの学習には隠れ層ユニットや層の深さは重要な要素であるため、隠れ層ユニットを持つSNNにおける学習課題を克服することは不可欠である。</br>
ネットワークモデルが大きくなり、組み込み型アプリケーションや自動車アプリケーションにそれらを移すことを考えるとき、そのモデルの電力効率はますます重要になってくる。こういった大規模ハードウェア開発が進んできていることもあり、エネルギー効率の良いSNNやバイナリRNNの研究需要というのは大きくなってきている。
本論文では、SNNの隠れ層を学習する際に困難になる理由、それらをうまく実装するために使用される様々な戦略や近似について紹介している。

#### 個人的注釈
- LIF（Leaky Integrate and Fire）モデル
  - SNNのニューロンモデルのひとつ。時々刻々と膜電位が上昇していきニューロンの閾値を超えた場合に次のニューロンへの発火を伝える様子を簡略化したモデル。</br>
  この他にもHH（Hodgkin-Haxley）モデル＜一番複雑＞や、Izhikevichモデル＜あまり使われない？＞などがある。
- ハードウェア実装
  - 多くはハードウェア言語によってFPGAなどに学習モデルを載せることを指す。バイナリで計算する利点として、ハードウェアで使用する乗算器が少なく済むという利点があるらしい。

## 2章 Understanding SNNs As RNNs
SNNをRNNの一種としてマッピングすることから始める。RNNとしてSNNを定式化することは、RNNの既存の学習則をSNNに適用させることにおいて重要な作業となる。また、概念的な学習則の理解のためにも役立つ。筆者らは、今後RNNという用語を広い意味で利用していく。具体的には、その状態が時間的に変化し、内部状態が回帰的な動的方程式を用いて表せるネットワーク全般を指すこととする。一般的なRNNの理解は、再帰結合を持ったネットワークがRNNであるというケースが多い。しかし、本質的な「再帰（リカレンス）」とは、再帰結合がない場合にも起こり得る。例えば、動的な内部状態を持つニューロンモデルを考えてみると、特定の時刻の状態（膜電位）は、前時刻の状態に依存したものになっている。本論文ではこのどちらのモデルにおいてもRNNという用語を適用することとする。（つまり一般的なSNNもRNNと呼ぶこともあるよということ）さらに、SNNとRNNの区別のために、再帰結合を持つ通常のネットワークはRCNN（Reccurrently Connected Neural Network）と呼ぶことを提案する。</br>
使用するニューロンモデルは、計算神経科学で広く使用されている電流ベースのシナプスを持つLIFモデル（LIF with current-based synapses）を使用する。 次に、このモデルを離散時間で再定式化し、バイナリ活性化関数を使用したRNNとの正式な等価性を示す。 LIFニューロンに詳しい読者は、3章まで飛ばして構わない。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGLRNN1.png" alt="RNNの伝播モデル" title="RNNの伝播モデル">
</div>

SNNやRNNは時系列的な内部接続性を持ったネットワークでありネットワークの内部状態a[n]は入力x[n]と一時刻前の内部状態a[n-1]の関数であると定義できる。</br>
一般的なRNNの構造は上に表示されている画像のようになり、計算モデルは下記で表される。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/RNNformula.png" alt="RNNの計算モデル" title="RNNの計算モデル">
</div>

シグマは活性化関数（SNNでは多くがヘビサイド関数）。Vが再帰重み、Wが順方向重みを表している。

l層のi番目のニューロンに対しては、以下の膜電位式で表す事ができる。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_mem1.png" alt="特定の膜電位の計算モデル" title="特定の膜電位の計算モデル">
</div>

Uは膜電位、U_resetは静止膜電位（膜電位が閾値シータを超えてニューロンが発火した場合、膜電位はこの値に戻る）Rは抵抗値、Iがニューロンに流れ込む入力電流。tau_memは膜電位用時定数。この式はニューロンの発火がない場合の状態を記述している。

上式を、ニューロンが発火した場合も考慮させると、以下の式になる。（スパイクが発火した場合（シータ - U_reset）だけ膜電位を減衰させる項を追加）

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_mem2.png" alt="膜電位の定式化" title="膜電位の定式化">
</div>

スパイクによる入力電流と膜電位の状態変化図が下の画像で示されている。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_synmem1.png" alt="スパイク入力電流と膜電位図" title="スパイク入力電流と膜電位図">
</div>

入力電流は通常、前ニューロンのシナプス電流の集合として表される。前ニューロンのシナプススパイクをSとすると、Sは以下のように表される。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_spike1.png" alt="シナプススパイクの定式化" title="シナプススパイクの定式化">
</div>

デルタはディラックのデルタ関数を示す。Cは時間窓を示し、sは時間窓内で発火した時刻を示す。つまり発火した回数が左辺の項の数と一致する。

シナプス電流は線形になると仮定して、次のように一次近似される。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_syn1.png" alt="シナプス電流の定式化" title="シナプス電流の定式化">
</div>

tau_synはシナプス電流用時定数。Wが前ニューロンからのシナプススパイクにかかる重み。Vが再帰結合から流れるシナプススパイクにかかる重み。

これをプログラム上で実行することを考えた場合（比較的小さな時間窓で実装することを考えた場合）、次のような式を記述できる。本論文では、Ureset=0, R=1, シータ=1を適用する。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_syn2.png" alt="シナプス電流の定式化、実装版" title="シナプス電流の定式化、実装版">
</div>

alpha = exp(dt/t_syn)で、0<alpha<1の範囲になるように設定する。膜電位に対しても次のように離散時間式に直す。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_mem3.png" alt="膜電位の定式化、実装版" title="膜電位の定式化、実装版">
</div>

beta = exp(dt/tau_mem)である。</br>
SNNのダイナミクスは上記の2式で表すことが出来る。これを図式化すると下のような図に展開される。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_unrollRNN1.png" alt="RNN伝搬の展開図" title="RNN伝搬の展開図">
</div>

横軸が時間、縦軸がユニット層である。SNNはRNNの特別なケースを構成することを説明してきた。 ただし、これまでのところ、特定の計算機能を実装するためにそれらのパラメータを設定する方法については説明していない。 これがこの記事の残りの部分であり、ここでは特定の機能の実装に向けてパラメータを体系的に変更するさまざまな学習アルゴリズムを紹介する。


## 3章 Method For Training RNNs
NNの学習において一般的に用いられているものについて説明する。</br>
損失関数に平均二乗誤差（MSE）を用いて、勾配降下法によってパラメータをチューニングしていく方法が多く採用されている。勾配降下法は、空間的な報酬による学習と時間的報酬による学習とで分けることができる。以下より、両方の場合についてのアルゴリズムについて説明していく。（credit=報酬、blame=罰）

#### A: Spatial Credit Assignment
RNNをトレーニングさせる方法として、報酬レイヤ（報酬ユニット）or罰レイヤ（罰ユニット）によって空間的な学習を可能とする。これをBPTT（BackPropagation Through Time）と呼ぶ。この学習は誤差逆伝搬法によって行われる。誤差逆伝搬法はすべてのレイヤに対しての計算グラフを保存しておくため、メモリを多く消費するという側面がある。

---
#### Box2: Gradient Backpropagation Rule for NNの理解
学習の課題は、データセット全体にわたってコスト関数Lを最小化することである。 ニューラルネットワークでは、これは勾配降下によって達成することができ、勾配降下は、勾配と反対の方向にネットワークパラメータＷを修正する。この更新規則はディープラーニングではよく用いられる手法であり、誤差逆伝搬法（Backpropagation）と呼ばれ、普遍的な更新式は以下のように示される。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_normalBP1.png" alt="BPの一般更新式" title="BPの一般更新式">
</div>

ここで、σ'は活性化関数の導関数であり、σ_i^(L)は出力層ニューロンiの誤差であり、損失関数Lに対するy_i^(L)の偏微分と解釈できる。この規則は、RNNにも適用することができ、展開されたRNNに対して時間ステップごとに順伝搬計算を行う。順伝搬重みと再帰重みを持つRNNに対しては、次のように定式化できる。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_grad1.png" alt="RNN導関数の定式化、実装版" title="RNN導関数の定式化、実装版">
</div>

a_iは各シナプス電流*重みを合計した入力電流。nは現在の時刻であり、Tは転置を表す。ここの再帰重みの導関数にある[s]は[m]の間違い？？？かも

---

#### B: Temporal Credit Assignment
RNNを訓練するときは、ネットワークの時間的依存性を考慮する必要がある。
- The backword method
  - この方法は図2（伝搬展開図）のように、ネットワークを展開して考えることで、空間的学習と同様の学習式を適用することが出来る。（Box2）空間的学習と同様の学習式を用いられるので、各種機械学習用フレームワークも同様に扱うことができる。
- The forward method
  - 多くの場合は、特定の時間内に必要な情報を順伝搬方向に伝達させる。例として、順伝搬における前方勾配は次の式のようになる。

  <div align="center">
  <img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_forwardweight.png" alt="順伝搬における重み更新式" title="順伝搬における重み更新式">
  </div>

回帰重みVに関する勾配も同様にして計算できる。回帰ノードを追加すると、保存する必要のある計算グラフが増加するため、必要メモリ、計算量が増大する。5章で説明するいくつかのアプローチで、これらの計算グラフを単純化させることができる。さらに、The forward methodは、セクション5章-Bで説明するように、学習規則が脳内のシナプス可塑性や３因子規則（three-factor rules）に基づいて構成されているため、生物学的な妥当性を持っている。

## 4章 Credit Assignment With Spiking Neurons
これまではRNN全般に対する学習方法を提示してきた。これらをSNNに適用する際に、問題点がふたつ存在する。１つ目はSNNの非線形性である。SNNの活性化関数にはヘビサイド関数が使用されるため、ここの導関数は0または無限になる。これにより誤差逆伝搬によって誤差情報を活性化関数より後ろに伝えることができなくなるという問題点がある。こういった問題点はSNN以外にもバイナリ型のネットワーク全般で発生する。下記画像の紫線が通常のヘビサイド関数の導関数グラフである。この図ではいくつかの代理勾配法を適用した例も示されており、それらでは勾配が消失していないことが確認できる。（原文参考文献あり）

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_derivative1.png" alt="ヘビサイド関数とその他勾配法の導関数" title="ヘビサイド関数とその他勾配法の導関数">
</div>

２つ目の課題は、最適化アルゴリズムの実装自体に関するものであり、計算時間の問題とも言い換えられる。標準的なBPは計算時間やメモリ消費が大きく、SNNで実装するにはコストが大きくなりすぎる場合がある。他にもニューロン型コンピュータの要件を満たさない可能性もある。こういった問題を解決する単純近似を以下で説明していく。

まず、１つ目の課題についての解決策としては、いくつか提案されている。
- 隠れ層用の完全ローカルな学習規則を用意する
- 従来のANNで学習させ、テスト段階でネットワークをSNNに切り替える
- ネットワークモデルを連続的で微分可能なものにする（平滑化アプローチ）
- 勾配の緩和として代理勾配（Surrogate Gradient）を定義する（SGアプローチ）

上２つに関してはこれまでいくつかのアプローチがなされてきた。したがってこの論文では後者２つについて注目していく。SG法を使用して機能的なSNNを構築する方法についての詳細な説明に入る前に、一般的な平滑化アプローチに関する既存の文献を確認する。

#### A: Smoothed Spiking Neural Networks
平滑化SNNの特徴は、それらの定式化が最適化に適した勾配を保証することである。平滑化SNNは以下の4モデルに分類できる。
- Soft nonlinearity Models
  - この手法は、滑らかなスパイク生成プロセスを明示的に含むすべてのスパイクニューロンモデルに直接適用できる。例としてはHodgkin-Huxley、Morris-Lecar、およびFitzHugh-Nagumoモデルが含まれる。Huh and Sejnowskiによって拡張型LIFモデルに適用された例もある。（原文参考文献あり）これらの平滑化後は、BPTTなど平均的な最適化法を通して学習することが可能になる。
- probabilistic Models
  - smooth Modelのもうひとつの例は、（binary probabilistic models）バイナリ確率モデルである。簡単に言えば、確率論により不連続な2値非線形性を効果的に平滑化し、期待値の勾配を定義することを可能にしている。主にボルツマンマシンや機械学習の文献で広範囲に研究されてきた手法である。しかし、平滑化の際に必要な注入ノイズが、最適化の課題として残っている。神経生物学的にもノイズが脳の学習にどのように影響するかは未解決である。
- rate code Models
    - スパイク密度基準の符号化方式を用いて勾配を得る方法もある。スパイク密度基準の入出力依存は、ニューロンのf-l曲線によって特徴づけられる。このアプローチにもいくつかの先行研究がある。（原文参考文献あり）</br>
    問題点としては、発火率の獲得に時間がかかる点がある。離散化ノイズを平均化するために時間窓についての試行を数回反復する場合もあることが、計算時間の増加につながる。また、この手法は確率モデルとの境界線があいまいである。理由としては、確率的ネットワークの出力にもレートコーディングが使用される場合があるからである。区別する方法としては、確率モデルは連続関数である発火確率密度に基づいて勾配を計算するが、決定論的ネットワークでは入力に対して出力のスパイク数は一定である。一定ではあるが、十分に大きな時間間関で平均すると結果として生じる発火率が入力電流の順連続関数として振る舞うため、勾配を求めることができる。
- single-spike temporal code Models
  - テンポラルコーディング（時間的なコーディング法）では、スパイク発火時刻に着目して入出力を決定する。この利点としては、レートコーディングと比較して計算時間を短縮できるという利点がある。時間符号化ネットワークの学習方法のアイデアは、SpikePropによって開拓された。また、最近ではnon-leaky-IFモデルに対してスパイクタイミング勾配を用いた学習法が提案された。（原文参考文献[34]）</br>
  うまくスパイクタイミングを定式化することで勾配の計算が可能になるが、いくつかの制限は存在する。例えば、SpikePropでは、各ユニットは1試行に対して1スパイクのみ発火することが求められた。こういった制限のあるネットワークにチューニングする必要性があるため、学習コストが上昇する場合もある。

#### B: Surrogate Gradients
代理勾配法では、平滑化アプローチと違って、ニューロンモデルや損失関数自体を再定義する代わりに、代理勾配を導入する。これによって最適化アルゴリズム自体を変更すること無く、既存のBPTTなどと組み合わせて学習することができる。しかし、学習時間やメモリ消費を改善するために、最適化アルゴリズムにも影響の出る代理勾配も存在する。このようなアプローチはグローバル損失をローカル関数で置き換える方法などが代表的である。また、代理勾配法は、隠れ層でどのような符号化方式が採用されているかに関係なく学習を行うことができる。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_SGgraph1.png" alt="第1層の重み補間グラフ" title="第1層の重み補間グラフ">
</div>

上図（a）は1層の重みを補間した際の損失関数グラフ。ネットワークは3層SNNで2-2-2。上図（b）は隠れ層での損失関数に対する勾配ノルムSGでは勾配が連続性を持っていることに注目したい。</br>
これらの代理損失は、最終的に初期店から最終点までの実際の損失が等しくなるようにスケーリングされる。代理損失は仮想的なものであり、適切な代理勾配は、近似によってもとのネットワークの真勾配から直接得ることができる。

標準的な勾配降下法と同様に、代理勾配学習は、ＢＰＴＴまたはforward methodのいずれかによって、空間的および時間的報酬割り当て問題に対処することができる。以下では、代理勾配法の原則や詳細の前に、既存の代理勾配法に基づいた手法について簡単に概説する。

- Surrogate deribatives for spiking nonlinearity
  - 一連の研究では、不連続スパイキング非線形性の課題を克服するためにSGが使用されてきた。これらの研究では、通常BPTTのような標準的なアルゴリズムが1つの小さな修正と共に使用される。アルゴリズム内では、スパイキング非線形性の導関数の各発生は滑らかな関数の導関数によって置き換えられる。これらのアプローチは、各種自動微分対応の機械学習フレームワークで実装できる。原文ではこの章でこれらの様々な手法について解説しているが、ここでは省略する。（原文参考文献あり）
- Surrogate Gradient affecting locality of the update rules
  - 前述の方法は、勾配消失を防ぐために代替の勾配を使用したが、BPTTなど既存の学習規則を適用することができた。しかし、誤差信号や教師信号のネットワーク伝搬について完全に変えてしまう方法も存在する。このような方法は、基本的には代理勾配法と同時に採用される。

どのようにして脳が報酬割当問題を解くことができるかを重視した研究では、根底にある生物学的制約を必要最小限満たした「ローカル」アルゴリズムがどれくらいの性能を達成できるかに焦点を当てている。（Box3）同様に、ニューロモフィックハードウェアに実装する際にも、単純化されたローカルアルゴリズムが要求されることがある。</br>
次のアプリケーションセクションより、真の勾配から大きく逸脱した代理勾配を用いて大幅に計算コストを削減する有望な代理勾配アプローチについて検討していく。

---
#### Box3: Local models of Computation
ここでは、局所性の概念を説明する。2つのニューロンAとBを想定し、NeuronAに次のように定義されたドメインDの関数を実装する。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_local1.png" alt="ニューロンAに実装する関数" title="ニューロンAに実装する関数">
</div>

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_local2.png" alt="ニューロンAに実装する関数動作" title="ニューロンAに実装する関数動作">
</div>

ここでS^B(t-T)はニューロンBにおけるT秒前の出力、U_A、U_Bはそれぞれの膜電位、W_(AB)はニューロンBからAまでの重み。重要なのは、D_(loc)は局所的であり、D_(nloc)は非局所的であるということ。変数S^B(t-T)は時間的に非局所的であり、U_BはニューロンＡに対して空間的に非局所的である。非局所情報は、特別な構造、例えばU_B専用の符号器および形式を通して送信できる。こうした非局所性は、計算を複雑化させる要因ともなるが、並列計算によって大規模計算を可能にすることもある。

---

#### 個人的注釈
- ニューロン型コンピュータ（ニューロモフィックハードウェア）
  - IntelのNeroNoteや＝＝＝
- 従来ANNをSNN変換
  - 日本語の論文でこの方法でMNIST？を学習させているものがあった。たしか三重大学の論文だったような。。再度見つけたらURLを載せる予定。
- SpikeProp
  - ネットワークモデルとして、一つのノードが重みと時間遅れという2つのパラメータを持っていることが特徴的。このモデルの日本語論文は多数ある。三重大学の研究室が積極的に研究を行っている様子。

## 5章 Applications
このセクションでは、ニューロンの内部連続時間ダイナミクスとイベント駆動型の性質の両方を利用した、SNNへの平滑化または代理勾配の例示的な応用例を紹介する。 イベント駆動型を利用した場合、入ってくるスパイクが活動を引き起こすまで、ネットワークが静止状態を保つことを可能にする。

#### A: Feedback alignment and random error backpropagation
BPの要件を緩和するアルゴリズムのひとつに、フィードバック同調、さらにもっと一般的にはランダムBPアルゴリズムがあります。これらは、BP規則の重みをランダムな重みで置き換えることによって非局所問題を回避する勾配BP規則の近似である。（Fig. 5b）

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_randomBP1.png" alt="ランダムエラーBP" title="ランダムエラーBP">
</div>

GはWと同じ次元を持つ固定のランダム行列である。Wをランダム行列Gに置き換えると、逆方向位相の（W^(T)(l)）への依存性がなくなり、規則がより局所的になる。一般的なバリエーションの1つは、後方伝播全体を各層への誤差のランダム伝播で置き換えることである。（Fig. 5c）

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_randomBP2.png" alt="ランダムエラーBP2" title="ランダムエラーBP2">
</div>

Hは適切な次元をもつ固定のランダム行列である。ランダムBPの一般的な理論的理解は依然として研究の最中だが、シミュレーション研究では、学習中に、ネットワークがフィードフォワード重みを（ランダム）フィードバック重みと部分的に一致するように調整し、エラー情報を効率よく伝えようとしていることを示している。これらの知見に基づいて、スパイキングニューロンのダイナミクスを持つ局所シナプス可塑性則を使用したランダムBPの非同期スパイク駆動適応が（原文参考文献[31]）で実証された。代理勾配を得るために、著者らは、ゼロ付近を除いてどこでもゼロである対称関数を用いて活性化関数の導関数を近似した。この学習則を使用するネットワークは非常によく機能し、BPで必要とされる順方向パスと逆方向パスの間の交替なしで連続的かつ非同期的に動作することが示された。しかし、NNに適用されるランダムBPに関する1つの重要な制限は、ニューロンとシナプスの時間的なダイナミクスが勾配で考慮されていないということである。次の規則、SuperSpikeではこの問題を解決することができる。

#### B: Supervised Learning with local three factor learning rules
SuperSpikeは、生物学的にもっともらしい3要素学習規則である。 「平滑化アプローチ」のカテゴリに分類される多くの既存の3要素ルールとは対照的に、SuperSpikeはいくつかの近似を組み合わせてより生物学的に説得力のあるものにするSGアプローチである。Superspikeの研究の動機としては、生物学的NNにおける学習のより深い理解が第一であったが、学習規則はBPTTに依存しないため、ハードウェア実装にとっても意義があるかもしれない。 具体的には、この規則はシナプス適格性トレースを使用して時間的報酬割り当て問題を解決する。</br>
SuperSpikeが順方向最適化手順の1つとして見なされる理由について、簡単に説明していく。SuperSpikeは、与えられた出力ニューロンが事前定義された時間にスパイクするように学習する一時的な教師あり学習タスクのために派生したものである。そのために、SuperSpikeは、カーネル関数イータ？（ε的ななにか）を用いて、一連の出力スパイク列S_k(t)とそれらに対応する教師スパイク列S_k^＊(t)のvan Rossum距離を最小にします。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_vanross1.png" alt="Superspikeにおける損失関数" title="Superspikeにおける損失関数">
</div>

オンライン勾配降下学習を実行するために、上記の損失関数の勾配を計算する必要がある。出力スパイク列の重みに関する微分について求めるため、2章終盤で述べたネットワークダイナミクス（入力電流Iや膜電位Uの離散式）を微分すると以下のような式が得られる。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_SSdyn1.png" alt="Superspikeにおけるダイナミクスの微分式" title="Superspikeにおけるダイナミクスの微分式">
</div>

上記方程式は、開始条件S_k[0]=U_k[0]=I_k[0]=0が与えられたときにすべての関連する導関数を生成するためにオンラインおよび時間的に前方にシミュレートできる動的システムを定義している。この式において重要なことは、2つの近似式を用いていることである。１つ目として、活性化関数は、σ'(U[n]-Θ)に置き換えられている。（4章序盤の導関数と膜電位Uの関係グラフを参照）2つ目は、上記膜電位式において、リセット項が消去されていることである。これらを定義を元にして最終的に得られる重みの更新式は以下のようになる。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_SSweight1.png" alt="Superspikeにおける重み更新式" title="Superspikeにおける重み更新式">
</div>

ここで、e_i[n]は、ε＊(S_i - S_i^＊)である。（＊は畳み込み積分）これらの重み更新は局所的な数量にのみ依存する（Box3）上記は、再帰結合と隠れ層のない単純な２層ネットワークについての式となる。RCNNまたは追加の隠れ層を持つネットワークで更新を計算するために同じ方法を適用すると、方程式はより複雑で非局所的になる。マルチレイヤネットワークに適用されたSuperSpikeは、ランダムBPのように出力レイヤから隠れユニットに直接エラー信号を伝播することでこの問題を回避する。（以下の図:c）

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_gradBP1.png" alt="Superspikeにおける重み更新式" title="Superspikeにおける重み更新式">
</div>

- Fig5. 勾配BPを緩和するための戦略（破線は固定のランダム接続）
  - (a)：通常の誤差逆伝搬。順方向パスと逆方向パスを交互に行い、順方向重みの転置を使用して各層にエラーを伝搬する。
  - (b)：FeedbackAlignmentでは、転置行列をランダム行列に置き換える。
  - (c)：Direct FeedbackAlignmentでは、エラーを最上層から隠れ層に直接伝搬する。
  - (d)：局所誤差（LocalError）では、各層で固定されたランダムな補助関数を使用する。

SuperSpikeは、すべての関連数量を時間的に前に伝播させることによって一時的な報酬割り当てを実現するが、空間報酬割り当てを実行するためにはランダムBPに依存する必要がある。ZenkeとGanguliによる研究（原文参考文献[2]）はフィードフォワードネットワークを中心としたものであったが、Bellecらの研究（原文参考文献[15]）では、同様の生物学的にもっともらしい3つの要素の規則がRCNNを効率的に訓練するためにも使用できることを示している。

#### C: Learning using local errors
実際には、Superspikeのパフォーマンスは、大規模なマルチレイヤネットワークではうまく拡張できていない。SuperSpikeの拡張性は、ローカルエラーを導入することによって向上させることができる。BPにおいて、重み更新式（Box2:1番目の式）での非局所成分は、σ_i^(l)[n]である。誤差逆伝搬を通じてこのエラー項を取得する代わりに、レイヤ固有の情報を使用してエラー項を取得する必要がある。 これを達成する１つの方法は、層ごとの損失L(l)[n]を定義し、この局所的な損失を使用して誤差を得ることである。そのようにな局所的エラー項σ^(l)は以下のように表される。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_localE1.png" alt="局所的エラー項" title="局所的エラー項">
</div>

ここで、y(ハット)^(l)[n]はレイヤの擬似的ターゲット、G^(l)はレイヤlのアクティビティベクトルを擬似ターゲットと同じ次元のベクトルに射影する固定ランダム行列である。 本質的に、この定式化は補助ランダム層が層lに接続されていると仮定しており、目標は補助ランダム層の出力と擬似ターゲットの間の食い違いを最小にするようにW(l)を修正することである。最も簡単な疑似ターゲットの設定例は、出力層のターゲットをそのまま持ってくることである。

最近では、このような関連アプローチが多数提案されてきている。局所誤差をSuperspikeと組み合わせた方法で時間的報酬割当問題を解いた例もある。（原文参考文献[4]）この方法では、単純化しながら多層SNNに対する非常に効率的なシナプス可塑性を構成する。これによって、機械学習フレームワークで既存の自動微分ライブラリを使用して深層畳み込み学習などにも応用することができる。（[4]や、SpyTorchチュートリアルで解説している部分）このアプローチは下図のようなDVSジェスチャデータセットでベンチマークされており、標準のBPまたはBPTTルールと同等のパフォーマンスを発揮している。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_DVS1.png" alt="局所的誤差によるDVSGデータセット学習" title="局所的誤差によるDVSGデータセット学習">
</div>

3層の畳込みSNNのフィードフォワード重み（緑色）は、固定ランダム行列を通し、生成された局所誤差を使用して代理勾配で学習される。（5章C式を参照）円形の矢印は、LIFの再帰結合を示し、再帰結合がある場合にはこちらも訓練する必要がある。（[4]の論文では再帰結合はない）このSNNモデルは、BPTT法より優れており（原文参考文献[13]）他のアプローチと比較して学習エポック数が少ない。

#### D: Learning using gradients of spike times
SNNの学習の難しさは、特定のスパイク列の発生による離散性によって導関数がゼロになることであり、それを解決するためにSG法を使用してきた。この他の方法として、スパイクに基づいた明確な数値量（大きさ）を使用することもできる。このような数値量のひとつがスパイクタイム（スパイク発生時刻）である。スパイク時間はニューロンの入力にスムーズに依存するように作ることができる連続量である。したがって、スパイク時間を処理することは代理勾配に対する補完的なアプローチとなり、代理勾配法と同じくネットワークの出力と入力の間の滑らかな微分の連鎖を得ることができる。以下の式では、リークのない積分と発火ニューロンを使用している。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_spiketime1.png" alt="スパイク時間による学習式" title="スパイク時間による学習式">
</div>

ここでt_i^(r)はニューロンjからくるスパイクのr^(th)時間である？？？。Θはヘビサイド関数である。</br>
この方法を用いて時間版XOR問題を解いてみる。1か0かの判断にはスパイク入力時刻が早いか遅いかで分類し入力する。（下図Fig.7）ネットワークの符号化方法は様々な方法があるが、ここではfirst-to-spike codeを使用する。first-to-spike codeのデコードでは、出力層ニューロンにおいて最初にスパイクするニューロンを選択する。

<div align="center">
<img src="https://github.com/Ry-Kurihara/spytorch/blob/images/SGL_stgraph1.png" alt="スパイク時間による学習グラフ" title="スパイク時間による学習フラフ">
</div>

XORの4つの入力パターンについて、(b)右側のプロットは出力層ニューロンの膜電位を示し、左側のプロットは隠れ層ニューロンの膜電位を示している。分類結果は、最初にスパイクが出力される出力ニューロンのインデックスでエンコードされる。（原文参考文献[34]）


#### 個人的注釈
- Van Rossum（ヴァン・ロッサム）
  - オランダ出身のアメリカ在住プログラマー。Pythonの発案者。
- first-to-spike code
  - SNNにおける符号化方法のひとつ。

## 6章 Conclusion
ここまで、SNNがRNNの枠組みの中でどのように研究されることができるかを概説し、それらを訓練するための成功したアプローチについて議論してきた。代理勾配法の普及によって、以前はRNNによって支配されていたアプリケーションにとってSNNがますます興味深いものになる重要な時代の幕開けとなる可能性がある。現段階でSNNがANNより広く使用されていないという事実は、主に訓練可能性のアルゴリズムの問題によるものだった。この記事では、SNNのトレーニング時に遭遇する問題に対処している様々な研究の概要を説明した。これらの問題を完全に解決することは、技術的にも、生物学的脳での学習に関連しても、直接的かつ広範囲の影響を及ぼすだろう。

## Acknowledgments
sponsored with

- 株式会社インテル
- アメリカ国立科学財団（National Science Foundation）
- スイス国立科学財団（the Swiss National Science Foundation Early Postdoc Mobility Grant）
- ウェルカム・トラスト（UK）
